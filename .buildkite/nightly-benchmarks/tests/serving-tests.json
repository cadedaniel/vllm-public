[
    {
        "test_name": "serving_spec_decode_tp8_k3",
        "qps_list": [8, 4, 2, 1, 0.5],
        "server_parameters": {
            "model": "meta-llama/Llama-2-70b-chat-hf",
            "disable_log_requests": "",
            "tensor_parallel_size": 8,
            "swap_space": 16,
            "speculative_model": "/mnt/local_storage/custom_models/xwjiang-82m",
            "num_speculative_tokens": 3,
            "speculative_draft_tensor_parallel_size": 1,
            "use_v2_block_manager": ""
        },
        "client_parameters": {
            "model": "meta-llama/Llama-2-70b-chat-hf",
            "backend": "vllm",
            "dataset_name": "sharegpt",
            "dataset_path": "./ShareGPT_V3_unfiltered_cleaned_split.json",
            "num_prompts": 200
        }
    },
    {
        "test_name": "serving_spec_decode_tp8_k4",
        "qps_list": [8, 4, 2, 1, 0.5],
        "server_parameters": {
            "model": "meta-llama/Llama-2-70b-chat-hf",
            "disable_log_requests": "",
            "tensor_parallel_size": 8,
            "swap_space": 16,
            "speculative_model": "/mnt/local_storage/custom_models/xwjiang-82m",
            "num_speculative_tokens": 4,
            "speculative_draft_tensor_parallel_size": 1,
            "use_v2_block_manager": ""
        },
        "client_parameters": {
            "model": "meta-llama/Llama-2-70b-chat-hf",
            "backend": "vllm",
            "dataset_name": "sharegpt",
            "dataset_path": "./ShareGPT_V3_unfiltered_cleaned_split.json",
            "num_prompts": 200
        }
    },
    {
        "test_name": "serving_spec_decode_tp8_k1",
        "qps_list": [8, 4, 2, 1, 0.5],
        "server_parameters": {
            "model": "meta-llama/Llama-2-70b-chat-hf",
            "disable_log_requests": "",
            "tensor_parallel_size": 8,
            "swap_space": 16,
            "speculative_model": "/mnt/local_storage/custom_models/xwjiang-82m",
            "num_speculative_tokens": 1,
            "speculative_draft_tensor_parallel_size": 1,
            "use_v2_block_manager": ""
        },
        "client_parameters": {
            "model": "meta-llama/Llama-2-70b-chat-hf",
            "backend": "vllm",
            "dataset_name": "sharegpt",
            "dataset_path": "./ShareGPT_V3_unfiltered_cleaned_split.json",
            "num_prompts": 200
        }
    },
    {
        "test_name": "serving_spec_decode_tp8_k2",
        "qps_list": [8, 4, 2, 1, 0.5],
        "server_parameters": {
            "model": "meta-llama/Llama-2-70b-chat-hf",
            "disable_log_requests": "",
            "tensor_parallel_size": 8,
            "swap_space": 16,
            "speculative_model": "/mnt/local_storage/custom_models/xwjiang-82m",
            "num_speculative_tokens": 2,
            "speculative_draft_tensor_parallel_size": 1,
            "use_v2_block_manager": ""
        },
        "client_parameters": {
            "model": "meta-llama/Llama-2-70b-chat-hf",
            "backend": "vllm",
            "dataset_name": "sharegpt",
            "dataset_path": "./ShareGPT_V3_unfiltered_cleaned_split.json",
            "num_prompts": 200
        }
    },
    {
        "test_name": "serving_spec_decode_tp8_baseline",
        "qps_list": [8, 4, 2, 1, 0.5],
        "server_parameters": {
            "model": "meta-llama/Llama-2-70b-chat-hf",
            "disable_log_requests": "",
            "tensor_parallel_size": 8,
            "swap_space": 16
        },
        "client_parameters": {
            "model": "meta-llama/Llama-2-70b-chat-hf",
            "backend": "vllm",
            "dataset_name": "sharegpt",
            "dataset_path": "./ShareGPT_V3_unfiltered_cleaned_split.json",
            "num_prompts": 200
        }
    },
    {
        "test_name": "serving_spec_decode_tp4_k1",
        "qps_list": [8, 4, 2, 1, 0.5],
        "server_parameters": {
            "model": "meta-llama/Llama-2-70b-chat-hf",
            "disable_log_requests": "",
            "tensor_parallel_size": 4,
            "swap_space": 16,
            "speculative_model": "/mnt/local_storage/custom_models/xwjiang-82m",
            "num_speculative_tokens": 1,
            "speculative_draft_tensor_parallel_size": 1,
            "use_v2_block_manager": ""
        },
        "client_parameters": {
            "model": "meta-llama/Llama-2-70b-chat-hf",
            "backend": "vllm",
            "dataset_name": "sharegpt",
            "dataset_path": "./ShareGPT_V3_unfiltered_cleaned_split.json",
            "num_prompts": 200
        }
    },
    {
        "test_name": "serving_spec_decode_tp4_k2",
        "qps_list": [8, 4, 2, 1, 0.5],
        "server_parameters": {
            "model": "meta-llama/Llama-2-70b-chat-hf",
            "disable_log_requests": "",
            "tensor_parallel_size": 4,
            "swap_space": 16,
            "speculative_model": "/mnt/local_storage/custom_models/xwjiang-82m",
            "num_speculative_tokens": 2,
            "speculative_draft_tensor_parallel_size": 1,
            "use_v2_block_manager": ""
        },
        "client_parameters": {
            "model": "meta-llama/Llama-2-70b-chat-hf",
            "backend": "vllm",
            "dataset_name": "sharegpt",
            "dataset_path": "./ShareGPT_V3_unfiltered_cleaned_split.json",
            "num_prompts": 200
        }
    },
    {
        "test_name": "serving_spec_decode_tp4_k3",
        "qps_list": [8, 4, 2, 1, 0.5],
        "server_parameters": {
            "model": "meta-llama/Llama-2-70b-chat-hf",
            "disable_log_requests": "",
            "tensor_parallel_size": 4,
            "swap_space": 16,
            "speculative_model": "/mnt/local_storage/custom_models/xwjiang-82m",
            "num_speculative_tokens": 3,
            "speculative_draft_tensor_parallel_size": 1,
            "use_v2_block_manager": ""
        },
        "client_parameters": {
            "model": "meta-llama/Llama-2-70b-chat-hf",
            "backend": "vllm",
            "dataset_name": "sharegpt",
            "dataset_path": "./ShareGPT_V3_unfiltered_cleaned_split.json",
            "num_prompts": 200
        }
    },
    {
        "test_name": "serving_spec_decode_tp4_k4",
        "qps_list": [8, 4, 2, 1, 0.5],
        "server_parameters": {
            "model": "meta-llama/Llama-2-70b-chat-hf",
            "disable_log_requests": "",
            "tensor_parallel_size": 4,
            "swap_space": 16,
            "speculative_model": "/mnt/local_storage/custom_models/xwjiang-82m",
            "num_speculative_tokens": 4,
            "speculative_draft_tensor_parallel_size": 1,
            "use_v2_block_manager": ""
        },
        "client_parameters": {
            "model": "meta-llama/Llama-2-70b-chat-hf",
            "backend": "vllm",
            "dataset_name": "sharegpt",
            "dataset_path": "./ShareGPT_V3_unfiltered_cleaned_split.json",
            "num_prompts": 200
        }
    },
    {
        "test_name": "serving_spec_decode_tp4_baseline",
        "qps_list": [8, 4, 2, 1, 0.5],
        "server_parameters": {
            "model": "meta-llama/Llama-2-70b-chat-hf",
            "disable_log_requests": "",
            "tensor_parallel_size": 4,
            "swap_space": 16
        },
        "client_parameters": {
            "model": "meta-llama/Llama-2-70b-chat-hf",
            "backend": "vllm",
            "dataset_name": "sharegpt",
            "dataset_path": "./ShareGPT_V3_unfiltered_cleaned_split.json",
            "num_prompts": 200
        }
    }
]
